{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main_Train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nhsto7Y33c23",
        "outputId": "3081dc2a-e79b-42a4-cf11-e1a60ff0470d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oi9J8g5glgnI"
      },
      "source": [
        "from os.path import join\n",
        "\n",
        "main_dir = \"/content/drive/MyDrive/Fire_Prediction/Fire_Mapping_Project-main\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlqW2m9Dklhp",
        "outputId": "4a9957b8-de28-44e8-bf63-25cea99f87a4"
      },
      "source": [
        "s = '/'\n",
        "model_dir = join(main_dir,\"model\")\n",
        "data_dir = join(main_dir, \"data\")\n",
        "\n",
        "print(\"model_dir\", model_dir)\n",
        "print(\"data_dir\", data_dir)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_dir /content/drive/MyDrive/Fire_Prediction/Fire_Mapping_Project-main/model\n",
            "data_dir /content/drive/MyDrive/Fire_Prediction/Fire_Mapping_Project-main/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkwBTS74JO_W"
      },
      "source": [
        ""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDbkaZsfk2Ou",
        "outputId": "da2a5ddd-b699-4e7d-a93c-1bfad58452dd"
      },
      "source": [
        "cd /content/drive/MyDrive/Fire_Prediction/Fire_Mapping_Project-main/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Fire_Prediction/Fire_Mapping_Project-main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnSmoJ1R-UIj"
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch import FloatTensor\n",
        "# import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "from net.unet import U_Net\n",
        "from net.attention_unet import AttU_Net\n",
        "from dataset import FireDataset\n",
        "\n",
        "def set_seed(args):\n",
        "    random.seed(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "\n",
        "def get_dataset(img_dir, mask_dir, transform_mode, transform_types, mode):\n",
        "    dataset_class = FireDataset(img_dir, mask_dir, transform_mode, transform_types, mode)\n",
        "    return dataset_class\n",
        "\n",
        "# +\n",
        "def evaluate(args, model, test_dataloader):\n",
        "    model.eval()\n",
        "    criterion = nn.BCELoss()\n",
        "    eval_losses = []\n",
        "    sensitivities = []\n",
        "    specificities = []\n",
        "    ppvs = []\n",
        "    npvs = []\n",
        "    f1s = []\n",
        "\n",
        "    \n",
        "    for cutoff in np.linspace(0,1,11):\n",
        "        temp_sens = [] #recall\n",
        "        temp_spec = [] \n",
        "        temp_ppv = [] #precision\n",
        "        temp_npv = []\n",
        "        temp_f1s = []\n",
        "\n",
        "\n",
        "        for step, (images, masks) in enumerate(test_dataloader):\n",
        "        \n",
        "          if args.cuda:\n",
        "              images = images.cuda(args.device_id)\n",
        "              masks = masks.cuda(args.device_id)\n",
        "        \n",
        "          with torch.no_grad():\n",
        "              output_masks = model(images)\n",
        "              output_masks = torch.sigmoid(output_masks)\n",
        "              loss = criterion(output_masks, masks)\n",
        "              eval_losses.append(loss.item())\n",
        "            \n",
        "              output_masks = output_masks.detach().cpu().numpy()\n",
        "              output_masks = np.where(output_masks > cutoff, 1, 0)\n",
        "              masks = masks.detach().cpu().numpy()\n",
        "          \n",
        "              #Scoring\n",
        "              tp = ((output_masks == 1) & (masks == 1)).sum()\n",
        "              tn = ((output_masks == 0) & (masks == 0)).sum()\n",
        "              fp = ((output_masks == 1) & (masks == 0)).sum()\n",
        "              fn = ((output_masks == 0) & (masks == 1)).sum()\n",
        "            \n",
        "              #print(\"tp = %d, tn = %d, fp = %d, fn = %d\" \\\n",
        "                    #%(tp, tn, fp ,fn))\n",
        "            \n",
        "              sensitivity = tp / (tp + fn) #recall\n",
        "              specificity = tn / (fp + tn)\n",
        "              if (tp + fp) == 0:\n",
        "                ppv = 1\n",
        "              else:\n",
        "                ppv = tp / (fp + tp) #precision\n",
        "              npv = tn / (fn + tn)\n",
        "              f1 = 2*tp/(2*tp + fp + fn)\n",
        "              \n",
        "              temp_sens.append(sensitivity)\n",
        "              temp_spec.append(specificity)\n",
        "              temp_ppv.append(ppv)\n",
        "              temp_npv.append(npv)\n",
        "              temp_f1s.append(f1)\n",
        "\n",
        "\n",
        "        sensitivities.append(np.mean(temp_sens))\n",
        "        specificities.append(np.mean(temp_spec))\n",
        "        ppvs.append(np.mean(temp_ppv))\n",
        "        npvs.append(np.mean(temp_npv))\n",
        "        f1s.append(np.mean(temp_f1s))  \n",
        "    \n",
        "    auc = np.trapz(np.flip(ppvs), np.flip(sensitivities))\n",
        "\n",
        "#     return np.mean(eval_losses)\n",
        "    return np.mean(eval_losses), np.array(sensitivities), np.mean(specificities), np.mean(f1s), np.array(ppvs), np.mean(npvs), auc\n",
        "\n",
        "\n",
        "# -\n",
        "\n",
        "def train(args, train_dataloader, test_dataloader):\n",
        "\n",
        "    epochs = args.epochs\n",
        "    batch_size = args.batch_size\n",
        "    learning_rate = args.lr\n",
        "    log_interval = args.log_interval\n",
        "\n",
        "    # Model\n",
        "    if args.net == 'unet':\n",
        "        model = U_Net(img_ch=1, output_ch=1)\n",
        "    if args.net == 'attn_unet':\n",
        "        model = AttU_Net(img_ch=1, output_ch=1)\n",
        "\n",
        "    if args.cuda:\n",
        "        model.cuda(args.device_id)\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Loss criterion - BCE: binary cross entropy loss, as 2 classes in mask\n",
        "    criterion = nn.BCELoss()\n",
        "\n",
        "\n",
        "    # Begin training\n",
        "    print(\"Model :\", args.net)\n",
        "    print(\"Cutoff :\", args.cutoff)\n",
        "    print(\"Train Dataloader size :\",len(train_dataloader))\n",
        "    print(\"Transform mode :\",args.transform_mode)\n",
        "    print(\"Batch size :\", batch_size)\n",
        "    print(\"Epochs :\",epochs)\n",
        "    print(\"Begin Training\")\n",
        "    model.train()\n",
        "    model.zero_grad()\n",
        "\n",
        "    best_eval_f1 = 0.5\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_losses = []\n",
        "        for step, (images, masks) in enumerate(train_dataloader):\n",
        "            model.train()\n",
        "\n",
        "            if args.cuda:\n",
        "                images = images.cuda(args.device_id)\n",
        "                masks = masks.cuda(args.device_id)\n",
        "\n",
        "            output_masks = model(images)\n",
        "            output_masks = torch.sigmoid(output_masks)\n",
        "            loss = criterion(output_masks, masks)\n",
        "            # print(loss)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            model.zero_grad()\n",
        "\n",
        "            epoch_losses.append(loss.item())\n",
        "\n",
        "        # Printing\n",
        "        if epoch % log_interval == 0:\n",
        "            current_epoch_loss = np.mean(epoch_losses)\n",
        "            eval_loss, eval_sens, eval_spec, eval_f1, eval_ppv, eval_npv, eval_auc = evaluate(args, model, test_dataloader)\n",
        "            rounded_sens = np.around(eval_sens, decimals = 3)\n",
        "            rounded_ppv = np.around(eval_ppv, decimals = 3)\n",
        "            print(\"Epoch %d, Loss %.3f, Eval: Loss %.3f, AUC %.3f\" \\\n",
        "                  %(epoch, current_epoch_loss, eval_loss, eval_auc))\n",
        "            print(f\"PPVs: {rounded_ppv}, Sensitivities: {rounded_sens}\")\n",
        "            #print(\"Epoch %d, Loss %.3f, Eval: Loss %.3f, Sens %.3f, Spec %.3f, F1 %.3f, PPV %.3f, NPV %.3f, AUC %.3f\" \\\n",
        "                  #%(epoch, current_epoch_loss, eval_loss, eval_sens, eval_spec, eval_f1, eval_ppv, eval_npv, eval_auc))\n",
        "\n",
        "            #Save the model with minimun evaluation sensitivity :\n",
        "            if epoch > 10 and eval_auc > 0.6:\n",
        "                # Save the model\n",
        "                print(\"Saving epoch %d model\"%(epoch))\n",
        "                torch.save(model.state_dict(), 'trained_model_'+str(epoch)+'_'+str(args.net))\n",
        "                #best_auc = eval_auc\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydvLubjQiWp1"
      },
      "source": [
        "class Args:\n",
        "  def __init__(self):\n",
        "    self.train_img_dir = join(data_dir, \"train_images\")\n",
        "    self.train_mask_dir = join(data_dir, \"train_masks\")\n",
        "    self.test_img_dir = join(data_dir, \"test_images\")\n",
        "    self.test_mask_dir = join(data_dir, \"test_masks\")\n",
        "\n",
        "    self.net = 'attn_unet'\n",
        "    self.epochs = 100\n",
        "    self.batch_size = 8\n",
        "    self.cutoff = 0.30\n",
        "    self.lr = 0.001\n",
        "    self.log_interval = 1\n",
        "    self.transform_mode = 'basic'\n",
        "    self.device_id = 0\n",
        "    self.seed = 10\n",
        "    self.transform_types = []#'crop_hflip_vflip'\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nR_AYr_bjMAX",
        "outputId": "dd3abdd4-faf7-4724-81c2-7de749601072"
      },
      "source": [
        "args = Args()\n",
        "print(vars(args))\n",
        "print(args.batch_size)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train_img_dir': '/content/drive/MyDrive/Fire_Prediction/Fire_Mapping_Project-main/data/train_images', 'train_mask_dir': '/content/drive/MyDrive/Fire_Prediction/Fire_Mapping_Project-main/data/train_masks', 'test_img_dir': '/content/drive/MyDrive/Fire_Prediction/Fire_Mapping_Project-main/data/test_images', 'test_mask_dir': '/content/drive/MyDrive/Fire_Prediction/Fire_Mapping_Project-main/data/test_masks', 'net': 'unet', 'epochs': 100, 'batch_size': 8, 'cutoff': 0.3, 'lr': 0.001, 'log_interval': 1, 'transform_mode': 'basic', 'device_id': 0, 'seed': 10, 'transform_types': []}\n",
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "VyrwyK59jYs6",
        "outputId": "5407ed43-d3b0-4451-83f7-6b83e28f7e8c"
      },
      "source": [
        "# Set CUDA\n",
        "args.cuda = True if torch.cuda.is_available() else False\n",
        "print(\"Cuda\",args.cuda)\n",
        "\n",
        "# Set seed\n",
        "set_seed(args)\n",
        "\n",
        "# Get datasets\n",
        "\n",
        "train_dataset = get_dataset(args.train_img_dir, args.train_mask_dir, args.transform_mode, transform_types=args.transform_types, mode=\"train\")\n",
        "test_dataset = get_dataset(args.test_img_dir, args.test_mask_dir, \"basic\", transform_types=[], mode=\"test\")\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "train(args, train_dataloader, test_dataloader)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cuda True\n",
            "Dataset mode train Transform basic Transform types []\n",
            "Dataset mode test Transform basic Transform types []\n",
            "Model : unet\n",
            "Cutoff : 0.3\n",
            "Train Dataloader size : 4\n",
            "Transform mode : basic\n",
            "Batch size : 8\n",
            "Epochs : 100\n",
            "Begin Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:79: RuntimeWarning: invalid value encountered in long_scalars\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-9466e074b8c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtest_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-26-438f4099c7e2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, train_dataloader, test_dataloader)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlog_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mcurrent_epoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0meval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_sens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_ppv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_npv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0mrounded_sens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_sens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mrounded_ppv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_ppv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-438f4099c7e2>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(args, model, test_dataloader)\u001b[0m\n\u001b[1;32m     56\u001b[0m               \u001b[0moutput_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m               \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m               \u001b[0meval_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m               \u001b[0moutput_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_masks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDmeG5Aqta16"
      },
      "source": [
        "dsfasdfasfdssdfasdffdd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzJoCeEGSBzK",
        "outputId": "37702ac0-6aea-4eeb-ba33-5cae9e1040cc"
      },
      "source": [
        "len(train_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0W9Afm3RwUH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "0bba2a3a-9ad2-49b9-f6f3-8a4000cbe2e4"
      },
      "source": [
        "eval_sens"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-517e698e04c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meval_sens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'eval_sens' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-X6eJvH4O91W"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4YSkvhx9NfC",
        "outputId": "d92129d2-4fb4-40d0-98b2-6653539e2f66"
      },
      "source": [
        "!python train.py --transform_types '[]' "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cuda True\n",
            "Dataset mode train Transform basic Transform types ['[]']\n",
            "Dataset mode test Transform basic Transform types []\n",
            "Model : unet\n",
            "Cutoff : 0.3\n",
            "Train Dataloader size : 4\n",
            "Transform mode : basic\n",
            "Transform types: ['[]']\n",
            "Batch size : 8\n",
            "Epochs : 100\n",
            "Begin Training\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "train.py:69: RuntimeWarning: invalid value encountered in long_scalars\n",
            "  npv = tn / (fn + tn)\n",
            "Epoch 0, Loss 0.580, Eval: Loss 0.630, Sens 1.000, Spec 0.000, F1 0.125, PPV 0.073, NPV nan\n",
            "Epoch 1, Loss 0.404, Eval: Loss 0.594, Sens 1.000, Spec 0.000, F1 0.125, PPV 0.073, NPV nan\n",
            "Epoch 2, Loss 0.364, Eval: Loss 0.557, Sens 1.000, Spec 0.000, F1 0.125, PPV 0.073, NPV nan\n",
            "Epoch 3, Loss 0.334, Eval: Loss 0.449, Sens 0.119, Spec 0.546, F1 0.047, PPV 0.032, NPV 0.880\n",
            "Epoch 4, Loss 0.307, Eval: Loss 0.522, Sens 0.105, Spec 0.367, F1 0.045, PPV 0.030, NPV 0.848\n",
            "Epoch 5, Loss 0.295, Eval: Loss 0.419, Sens 0.076, Spec 0.523, F1 0.035, PPV 0.024, NPV 0.872\n",
            "Epoch 6, Loss 0.272, Eval: Loss 0.413, Sens 0.049, Spec 0.585, F1 0.030, PPV 0.022, NPV 0.882\n",
            "Epoch 7, Loss 0.266, Eval: Loss 0.647, Sens 0.921, Spec 0.601, F1 0.210, PPV 0.148, NPV 0.972\n",
            "Epoch 8, Loss 0.257, Eval: Loss 0.513, Sens 0.924, Spec 0.602, F1 0.208, PPV 0.151, NPV 0.973\n",
            "Epoch 9, Loss 0.286, Eval: Loss 0.345, Sens 0.007, Spec 0.976, F1 0.009, PPV 0.027, NPV 0.926\n",
            "Epoch 10, Loss 0.262, Eval: Loss 0.319, Sens 0.004, Spec 0.992, F1 0.006, PPV 0.018, NPV 0.926\n",
            "Epoch 11, Loss 0.238, Eval: Loss 0.307, Sens 0.000, Spec 0.997, F1 0.000, PPV 0.033, NPV 0.927\n",
            "Epoch 12, Loss 0.223, Eval: Loss 0.300, Sens 0.001, Spec 0.999, F1 0.003, PPV 0.396, NPV 0.927\n",
            "Epoch 13, Loss 0.214, Eval: Loss 0.295, Sens 0.014, Spec 0.998, F1 0.026, PPV 0.579, NPV 0.928\n",
            "Epoch 14, Loss 0.214, Eval: Loss 1.303, Sens 0.686, Spec 0.865, F1 0.294, PPV 0.233, NPV 0.960\n",
            "train.py:68: RuntimeWarning: invalid value encountered in long_scalars\n",
            "  ppv = tp / (fp + tp)\n",
            "Epoch 15, Loss 0.207, Eval: Loss 0.480, Sens 0.000, Spec 1.000, F1 0.000, PPV nan, NPV 0.927\n",
            "Epoch 16, Loss 0.204, Eval: Loss 0.270, Sens 0.100, Spec 0.975, F1 0.162, PPV 0.520, NPV 0.936\n",
            "Epoch 17, Loss 0.192, Eval: Loss 0.281, Sens 0.023, Spec 0.999, F1 0.044, PPV 0.599, NPV 0.928\n",
            "Epoch 18, Loss 0.188, Eval: Loss 0.262, Sens 0.039, Spec 0.994, F1 0.074, PPV 0.639, NPV 0.931\n",
            "Epoch 19, Loss 0.183, Eval: Loss 0.255, Sens 0.077, Spec 0.992, F1 0.137, PPV 0.668, NPV 0.934\n",
            "Epoch 20, Loss 0.180, Eval: Loss 0.245, Sens 0.033, Spec 0.994, F1 0.061, PPV 0.686, NPV 0.931\n",
            "Epoch 21, Loss 0.185, Eval: Loss 0.237, Sens 0.083, Spec 0.992, F1 0.143, PPV 0.687, NPV 0.937\n",
            "Epoch 22, Loss 0.175, Eval: Loss 0.252, Sens 0.219, Spec 0.982, F1 0.310, PPV 0.644, NPV 0.945\n",
            "Epoch 23, Loss 0.170, Eval: Loss 0.238, Sens 0.234, Spec 0.985, F1 0.343, PPV 0.646, NPV 0.947\n",
            "Epoch 24, Loss 0.168, Eval: Loss 0.237, Sens 0.594, Spec 0.936, F1 0.424, PPV 0.381, NPV 0.962\n",
            "Epoch 25, Loss 0.166, Eval: Loss 0.273, Sens 0.911, Spec 0.793, F1 0.294, PPV 0.217, NPV 0.973\n",
            "Epoch 26, Loss 0.166, Eval: Loss 0.266, Sens 0.923, Spec 0.797, F1 0.320, PPV 0.233, NPV 0.977\n",
            "Epoch 27, Loss 0.157, Eval: Loss 0.319, Sens 0.492, Spec 0.760, F1 0.193, PPV 0.167, NPV 0.954\n",
            "Epoch 28, Loss 0.159, Eval: Loss 0.276, Sens 0.654, Spec 0.813, F1 0.280, PPV 0.227, NPV 0.968\n",
            "Epoch 29, Loss 0.150, Eval: Loss 0.243, Sens 0.595, Spec 0.881, F1 0.306, PPV 0.256, NPV 0.966\n",
            "Epoch 30, Loss 0.154, Eval: Loss 0.219, Sens 0.823, Spec 0.894, F1 0.408, PPV 0.334, NPV 0.973\n",
            "Epoch 31, Loss 0.155, Eval: Loss 0.233, Sens 0.465, Spec 0.910, F1 0.259, PPV nan, NPV 0.958\n",
            "Epoch 32, Loss 0.157, Eval: Loss 0.721, Sens 0.947, Spec 0.574, F1 0.211, PPV 0.146, NPV 0.979\n",
            "Epoch 33, Loss 0.142, Eval: Loss 0.746, Sens 0.940, Spec 0.650, F1 0.243, PPV 0.174, NPV 0.978\n",
            "Epoch 34, Loss 0.146, Eval: Loss 0.284, Sens 0.252, Spec 0.941, F1 0.116, PPV 0.313, NPV 0.935\n",
            "Epoch 35, Loss 0.152, Eval: Loss 0.212, Sens 0.415, Spec 0.973, F1 0.409, PPV 0.602, NPV 0.957\n",
            "Epoch 36, Loss 0.143, Eval: Loss 0.209, Sens 0.763, Spec 0.933, F1 0.497, PPV 0.491, NPV 0.970\n",
            "Epoch 37, Loss 0.135, Eval: Loss 0.219, Sens 0.319, Spec 0.961, F1 0.326, PPV 0.622, NPV 0.955\n",
            "Epoch 38, Loss 0.132, Eval: Loss 0.213, Sens 0.582, Spec 0.919, F1 0.351, PPV 0.487, NPV 0.966\n",
            "Epoch 39, Loss 0.135, Eval: Loss 0.304, Sens 0.929, Spec 0.829, F1 0.374, PPV 0.287, NPV 0.979\n",
            "Epoch 40, Loss 0.148, Eval: Loss 0.311, Sens 0.318, Spec 0.878, F1 0.140, PPV 0.283, NPV 0.939\n",
            "Epoch 41, Loss 0.132, Eval: Loss 0.244, Sens 0.505, Spec 0.922, F1 0.354, PPV 0.378, NPV 0.956\n",
            "Epoch 42, Loss 0.139, Eval: Loss 0.216, Sens 0.339, Spec 0.983, F1 0.380, PPV 0.641, NPV 0.949\n",
            "Epoch 43, Loss 0.135, Eval: Loss 0.222, Sens 0.440, Spec 0.969, F1 0.404, PPV 0.517, NPV 0.949\n",
            "Epoch 44, Loss 0.142, Eval: Loss 0.248, Sens 0.553, Spec 0.908, F1 0.337, PPV 0.316, NPV 0.952\n",
            "Epoch 45, Loss 0.139, Eval: Loss 0.244, Sens 0.078, Spec 0.991, F1 0.128, PPV 0.722, NPV 0.932\n",
            "Epoch 46, Loss 0.120, Eval: Loss 0.224, Sens 0.300, Spec 0.973, F1 0.351, PPV 0.635, NPV 0.945\n",
            "Epoch 47, Loss 0.137, Eval: Loss 0.235, Sens 0.101, Spec 0.992, F1 0.169, PPV 0.679, NPV 0.935\n",
            "Epoch 48, Loss 0.125, Eval: Loss 0.218, Sens 0.235, Spec 0.988, F1 0.283, PPV nan, NPV 0.944\n",
            "Epoch 49, Loss 0.117, Eval: Loss 0.216, Sens 0.642, Spec 0.899, F1 0.366, PPV 0.306, NPV 0.973\n",
            "Epoch 50, Loss 0.120, Eval: Loss 0.349, Sens 0.942, Spec 0.763, F1 0.319, PPV 0.230, NPV 0.980\n",
            "Epoch 51, Loss 0.128, Eval: Loss 0.259, Sens 0.880, Spec 0.849, F1 0.366, PPV 0.301, NPV 0.968\n",
            "Epoch 52, Loss 0.135, Eval: Loss 0.286, Sens 0.834, Spec 0.830, F1 0.262, PPV 0.237, NPV 0.962\n",
            "Epoch 53, Loss 0.116, Eval: Loss 0.271, Sens 0.591, Spec 0.850, F1 0.294, PPV 0.262, NPV 0.962\n",
            "Epoch 54, Loss 0.115, Eval: Loss 0.272, Sens 0.483, Spec 0.845, F1 0.258, PPV 0.213, NPV 0.957\n",
            "Epoch 55, Loss 0.117, Eval: Loss 0.253, Sens 0.402, Spec 0.964, F1 0.276, PPV 0.360, NPV 0.948\n",
            "Epoch 56, Loss 0.105, Eval: Loss 0.219, Sens 0.916, Spec 0.875, F1 0.421, PPV 0.335, NPV 0.977\n",
            "Epoch 57, Loss 0.106, Eval: Loss 0.270, Sens 0.057, Spec 0.984, F1 0.099, PPV nan, NPV 0.935\n",
            "Epoch 58, Loss 0.103, Eval: Loss 0.205, Sens 0.703, Spec 0.930, F1 0.527, PPV 0.569, NPV 0.969\n",
            "Saving epoch 58 model\n",
            "Epoch 59, Loss 0.100, Eval: Loss 0.330, Sens 0.935, Spec 0.761, F1 0.294, PPV 0.208, NPV 0.978\n",
            "Epoch 60, Loss 0.101, Eval: Loss 0.261, Sens 0.175, Spec 0.979, F1 0.224, PPV 0.654, NPV 0.936\n",
            "Epoch 61, Loss 0.099, Eval: Loss 0.310, Sens 0.000, Spec 1.000, F1 0.001, PPV nan, NPV 0.927\n",
            "Epoch 62, Loss 0.098, Eval: Loss 0.314, Sens 0.001, Spec 1.000, F1 0.001, PPV nan, NPV 0.927\n",
            "Epoch 63, Loss 0.094, Eval: Loss 0.246, Sens 0.276, Spec 0.987, F1 0.352, PPV 0.738, NPV 0.943\n",
            "Epoch 64, Loss 0.097, Eval: Loss 0.238, Sens 0.189, Spec 0.972, F1 0.253, PPV 0.750, NPV 0.944\n",
            "Epoch 65, Loss 0.093, Eval: Loss 0.271, Sens 0.051, Spec 0.974, F1 0.084, PPV 0.613, NPV 0.932\n",
            "Epoch 66, Loss 0.086, Eval: Loss 0.256, Sens 0.230, Spec 0.969, F1 0.279, PPV 0.664, NPV 0.943\n",
            "Epoch 67, Loss 0.091, Eval: Loss 0.291, Sens 0.034, Spec 0.984, F1 0.064, PPV nan, NPV 0.929\n",
            "Epoch 68, Loss 0.083, Eval: Loss 0.321, Sens 0.200, Spec 0.988, F1 0.008, PPV nan, NPV 0.927\n",
            "Epoch 69, Loss 0.101, Eval: Loss 0.429, Sens 0.935, Spec 0.837, F1 0.393, PPV 0.295, NPV 0.983\n",
            "Epoch 70, Loss 0.095, Eval: Loss 0.243, Sens 0.705, Spec 0.925, F1 0.456, PPV 0.536, NPV 0.967\n",
            "Epoch 71, Loss 0.094, Eval: Loss 0.292, Sens 0.463, Spec 0.869, F1 0.244, PPV 0.312, NPV 0.958\n",
            "Epoch 72, Loss 0.089, Eval: Loss 0.219, Sens 0.870, Spec 0.902, F1 0.511, PPV 0.452, NPV 0.973\n",
            "Epoch 73, Loss 0.084, Eval: Loss 0.233, Sens 0.357, Spec 0.965, F1 0.233, PPV nan, NPV 0.952\n",
            "Epoch 74, Loss 0.078, Eval: Loss 0.258, Sens 0.606, Spec 0.943, F1 0.370, PPV 0.575, NPV 0.955\n",
            "Epoch 75, Loss 0.070, Eval: Loss 0.192, Sens 0.825, Spec 0.913, F1 0.563, PPV 0.546, NPV 0.981\n",
            "Saving epoch 75 model\n",
            "Epoch 76, Loss 0.072, Eval: Loss 0.229, Sens 0.906, Spec 0.893, F1 0.467, PPV 0.390, NPV 0.978\n",
            "Epoch 77, Loss 0.076, Eval: Loss 0.268, Sens 0.186, Spec 0.983, F1 0.225, PPV 0.680, NPV 0.942\n",
            "Epoch 78, Loss 0.082, Eval: Loss 0.319, Sens 0.024, Spec 0.985, F1 0.042, PPV nan, NPV 0.931\n",
            "Epoch 79, Loss 0.067, Eval: Loss 0.221, Sens 0.369, Spec 0.981, F1 0.407, PPV 0.634, NPV 0.951\n",
            "Epoch 80, Loss 0.077, Eval: Loss 0.225, Sens 0.706, Spec 0.954, F1 0.547, PPV 0.643, NPV 0.956\n",
            "Epoch 81, Loss 0.071, Eval: Loss 0.286, Sens 0.143, Spec 0.961, F1 0.124, PPV 0.454, NPV 0.935\n",
            "Epoch 82, Loss 0.069, Eval: Loss 0.255, Sens 0.198, Spec 0.972, F1 0.279, PPV 0.672, NPV 0.942\n",
            "Epoch 83, Loss 0.069, Eval: Loss 0.235, Sens 0.219, Spec 0.981, F1 0.243, PPV 0.677, NPV 0.951\n",
            "Epoch 84, Loss 0.069, Eval: Loss 0.238, Sens 0.775, Spec 0.940, F1 0.552, PPV 0.598, NPV 0.968\n",
            "Epoch 85, Loss 0.071, Eval: Loss 0.295, Sens 0.173, Spec 0.980, F1 0.261, PPV nan, NPV 0.941\n",
            "Epoch 86, Loss 0.064, Eval: Loss 0.290, Sens 0.068, Spec 0.997, F1 0.114, PPV nan, NPV 0.937\n",
            "Epoch 87, Loss 0.059, Eval: Loss 0.264, Sens 0.178, Spec 0.985, F1 0.228, PPV 0.677, NPV 0.940\n",
            "Epoch 88, Loss 0.068, Eval: Loss 0.264, Sens 0.527, Spec 0.934, F1 0.363, PPV 0.433, NPV 0.957\n",
            "Epoch 89, Loss 0.055, Eval: Loss 0.339, Sens 0.092, Spec 0.975, F1 0.142, PPV nan, NPV 0.936\n",
            "Epoch 90, Loss 0.051, Eval: Loss 0.238, Sens 0.388, Spec 0.972, F1 0.419, PPV 0.623, NPV 0.954\n",
            "Epoch 91, Loss 0.057, Eval: Loss 0.226, Sens 0.477, Spec 0.969, F1 0.513, PPV 0.674, NPV 0.959\n",
            "Epoch 92, Loss 0.053, Eval: Loss 0.343, Sens 0.066, Spec 0.987, F1 0.116, PPV 0.632, NPV 0.931\n",
            "Epoch 93, Loss 0.047, Eval: Loss 0.235, Sens 0.645, Spec 0.945, F1 0.487, PPV 0.627, NPV 0.958\n",
            "Epoch 94, Loss 0.057, Eval: Loss 0.278, Sens 0.433, Spec 0.961, F1 0.260, PPV 0.632, NPV 0.949\n",
            "Epoch 95, Loss 0.077, Eval: Loss 0.265, Sens 0.610, Spec 0.914, F1 0.361, PPV 0.349, NPV 0.965\n",
            "Epoch 96, Loss 0.068, Eval: Loss 0.523, Sens 0.564, Spec 0.755, F1 0.228, PPV 0.216, NPV 0.960\n",
            "Epoch 97, Loss 0.056, Eval: Loss 0.299, Sens 0.883, Spec 0.888, F1 0.398, PPV 0.323, NPV 0.971\n",
            "Epoch 98, Loss 0.058, Eval: Loss 0.257, Sens 0.863, Spec 0.930, F1 0.546, PPV 0.507, NPV 0.969\n",
            "Epoch 99, Loss 0.054, Eval: Loss 0.282, Sens 0.196, Spec 0.982, F1 0.242, PPV nan, NPV 0.951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwIQcrT5k0Vy",
        "outputId": "43a2e348-a78a-418f-f302-ed7f37cea8e4"
      },
      "source": [
        "!python eval.py --trained_model trained_model_69_unet --net unet --test_img_dir data/train_images --test_mask_dir data/train_masks"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cuda True\n",
            "Dataset mode test Transform basic Transform types []\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "eval.py:125: RuntimeWarning: invalid value encountered in long_scalars\n",
            "  npv = tnsum / (fnsum + tnsum)\n",
            "cutoffs used:  [0.   0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1  0.11 0.12 0.13\n",
            " 0.14 0.15 0.16 0.17 0.18 0.19 0.2  0.21 0.22 0.23 0.24 0.25 0.26 0.27\n",
            " 0.28 0.29 0.3  0.31 0.32 0.33 0.34 0.35 0.36 0.37 0.38 0.39 0.4  0.41\n",
            " 0.42 0.43 0.44 0.45 0.46 0.47 0.48 0.49 0.5  0.51 0.52 0.53 0.54 0.55\n",
            " 0.56 0.57 0.58 0.59 0.6  0.61 0.62 0.63 0.64 0.65 0.66 0.67 0.68 0.69\n",
            " 0.7  0.71 0.72 0.73 0.74 0.75 0.76 0.77 0.78 0.79 0.8  0.81 0.82 0.83\n",
            " 0.84 0.85 0.86 0.87 0.88 0.89 0.9  0.91 0.92 0.93 0.94 0.95 0.96 0.97\n",
            " 0.98 0.99 1.  ]\n",
            "Eval loss:  [0.2606903314590454, 0.2078736126422882, 0.023239772766828537, 0.7107019424438477, 0.36957094073295593, 0.03297511488199234, 0.1036800742149353, 0.14405623078346252, 0.029631169512867928, 0.3173105716705322, 0.5520241856575012, 0.19912832975387573, 0.013564655557274818, 0.23112937808036804, 0.1097935140132904, 0.030701883137226105, 0.16811609268188477, 0.018787089735269547, 0.059573955833911896, 1.2334442138671875, 0.34784185886383057, 0.041902683675289154, 0.295676589012146, 0.303631067276001, 0.2963583171367645, 0.33541491627693176, 1.4003214836120605, 0.016191549599170685, 0.018262624740600586, 0.8371416330337524]\n",
            "Sensitivity:  [1.0, 1.0, 0.9939652870493992, 0.9875300400534045, 0.9837116154873164, 0.9806675567423231, 0.977690253671562, 0.9749666221628839, 0.9724432576769025, 0.9701068090787717, 0.9676769025367156, 0.9648197596795728, 0.9626702269692924, 0.9607877169559412, 0.9590387182910547, 0.9573297730307077, 0.955607476635514, 0.9540587449933244, 0.9525100133511348, 0.9509612817089452, 0.9495460614152202, 0.9481842456608812, 0.9467423230974633, 0.9453137516688919, 0.9437783711615487, 0.9423230974632844, 0.9407877169559412, 0.9393991989319093, 0.9380774365821095, 0.9367289719626168, 0.9352469959946595, 0.9338985313751669, 0.9322963951935914, 0.9309212283044058, 0.9295193591455274, 0.9279572763684913, 0.9259679572763685, 0.9242723631508678, 0.92260347129506, 0.9206275033377838, 0.9185847797062751, 0.9167556742323097, 0.9148331108144192, 0.912630173564753, 0.9105874499332444, 0.9086381842456609, 0.9067423230974633, 0.904712950600801, 0.9032176234979973, 0.9010413885180241, 0.8990520694259012, 0.8971161548731642, 0.895260347129506, 0.8931508678237651, 0.8909479305740988, 0.8887449933244326, 0.886475300400534, 0.8841388518024033, 0.8817222963951936, 0.8789452603471295, 0.8765020026702269, 0.8738985313751669, 0.8709345794392523, 0.8683311081441922, 0.865113484646195, 0.8623898531375167, 0.859452603471295, 0.8559679572763685, 0.8525767690253672, 0.8490921228304406, 0.845634178905207, 0.8425901201602136, 0.8392656875834446, 0.8358611481975968, 0.8327236315086782, 0.8289586114819759, 0.8253137516688919, 0.821388518024032, 0.8178104138851803, 0.8134846461949266, 0.8091188251001336, 0.8046595460614152, 0.7997463284379173, 0.7945927903871829, 0.7888918558077437, 0.7836315086782376, 0.7769025367156208, 0.7703871829105474, 0.7634846461949266, 0.7556608811748998, 0.7473831775700934, 0.7378237650200267, 0.7272229639519359, 0.7147530040053405, 0.700694259012016, 0.6830040053404539, 0.661588785046729, 0.6346061415220293, 0.5952469959946596, 0.5227369826435248, 0.0]\n",
            "Specificity: [0.0, 0.1073098744467324, 0.7642412518043816, 0.8127644120871949, 0.8288068222414785, 0.838633080500537, 0.8457506845503027, 0.8511094361841176, 0.8555124766242926, 0.8592622597224409, 0.8625075949224283, 0.8652635243341046, 0.867744935241031, 0.8699835235175329, 0.8719894963095796, 0.8738326919843282, 0.8754905473770053, 0.8770688944747644, 0.8785419468035786, 0.8798968111264338, 0.8812248145388438, 0.8825087660581238, 0.8837201931192017, 0.8849547205632625, 0.886196769062248, 0.8873598464845246, 0.8885148656336677, 0.8896634381643039, 0.8907502306009162, 0.8918418580014086, 0.8929173688556339, 0.8939176691606127, 0.8949496653399167, 0.8959257908254948, 0.8969448937677853, 0.8979645339282846, 0.8990169443995271, 0.9001268372191221, 0.9012474744028954, 0.9023869142239802, 0.9035370984092431, 0.9047646420165882, 0.9060485935358682, 0.9072863442891824, 0.9085525676075685, 0.9098268491990882, 0.9110823281532963, 0.9122556127215421, 0.913349926213079, 0.9143910551019345, 0.9153961903707933, 0.9164099211309947, 0.9174172052726893, 0.9184089100863256, 0.9193807378262324, 0.920360086621064, 0.9213824128726078, 0.9223252308292339, 0.92331210067899, 0.9242817795460614, 0.9252557561588038, 0.9261786970417005, 0.9270839097237032, 0.9280041645155555, 0.9289142121614383, 0.929837153044335, 0.9307348446714132, 0.9316395201352071, 0.9325656843273571, 0.9334977579198052, 0.9344411130946402, 0.9354005848157422, 0.9363917524111697, 0.9373286609674978, 0.9382886699068087, 0.9392701675744759, 0.9402489791510985, 0.9412202696727965, 0.9422200327595663, 0.9432396729200657, 0.9442845623363835, 0.9453267656616567, 0.9464259141170738, 0.9475718005566655, 0.9487730204717743, 0.9499489911310646, 0.9511942629393034, 0.9524690817490321, 0.9538674607468085, 0.9553426619484582, 0.9569817147038235, 0.9587749490851443, 0.9606530639434717, 0.9627788363961038, 0.9650765186755852, 0.967762072501895, 0.9709225272248758, 0.9746336306119828, 0.9791865549324421, 0.9852769977667839, 1.0]\n",
            "F1:  [0.07448137741822089, 0.08269435657939045, 0.2531388186651116, 0.29741412240598, 0.3153799069440937, 0.32737945343159647, 0.3364878059987823, 0.3435856176307296, 0.3495923838047858, 0.35484548366932334, 0.35941811942585533, 0.3631689905495152, 0.3667650926144933, 0.37010293637385216, 0.3731377397302969, 0.3759480098674294, 0.3784614083047361, 0.38092369691994415, 0.38322455885907664, 0.385331573309674, 0.3874600260409573, 0.3895486284426063, 0.3914933790464833, 0.3935151478099451, 0.3955437054279615, 0.3974625020765698, 0.39936183718346896, 0.4013221311522162, 0.4031974842478567, 0.40509713012174103, 0.4069385787067428, 0.40868206184362355, 0.41042806679323135, 0.4121482234582715, 0.4139770240700219, 0.41577211017625926, 0.4175132213021741, 0.41951787077773334, 0.42158468695187984, 0.4236137561586947, 0.4256732928707983, 0.42803266425632713, 0.43053539675658015, 0.43285618847696755, 0.43534709744133127, 0.437934551444778, 0.44053449226478125, 0.44290410923089996, 0.4452994125294147, 0.4473195821623628, 0.44934005952142636, 0.4514330247369765, 0.45356773246572285, 0.4555868071398898, 0.4575385670209119, 0.45953912851383444, 0.461668967003779, 0.4635625759076543, 0.46558403333204085, 0.4674344464246409, 0.4694617458399182, 0.47129089279221226, 0.47293936823484206, 0.4748096395745271, 0.4764152504053026, 0.4782948348186022, 0.4800265467588346, 0.4815725923060456, 0.48325469288603506, 0.484942067277448, 0.48670621503657713, 0.48873607013141895, 0.49078715198076234, 0.4926406074793933, 0.4947271984548451, 0.49664445635393584, 0.4986387780865455, 0.5005105008603261, 0.502683539317544, 0.5046255269456614, 0.5066843913817753, 0.508727948003714, 0.5108260917766048, 0.5130448650256242, 0.5152783591460862, 0.5176727920585992, 0.5196950955394103, 0.5220058079049024, 0.5247341230879343, 0.5274197907056927, 0.5307198217629352, 0.5341975147534328, 0.5376707088953709, 0.5415233663766943, 0.545579292062997, 0.5498801500542818, 0.554970069269063, 0.5603536693191865, 0.563544780600024, 0.5535596886730431, 0.0]\n",
            "PPV:  [0.03868120336242428, 0.043130502882085, 0.14503827204027284, 0.175069941821659, 0.18779342723004694, 0.19648661011644425, 0.2032134978007798, 0.20853799232386, 0.21310098861585003, 0.2171344386138969, 0.22069467408415622, 0.22368286650839295, 0.22653626107091354, 0.22919539717371434, 0.23162945478466124, 0.23390103634886825, 0.23595479689591287, 0.23796821717817562, 0.23986484214773224, 0.24161781866536405, 0.24338669605152388, 0.24512808830534097, 0.24676798012242526, 0.24847519248720845, 0.25020263550032384, 0.25184386964635525, 0.25348216469775675, 0.2551659860886468, 0.25678303072829867, 0.25842845619191795, 0.26004350763610984, 0.26157470598133986, 0.2631342934876815, 0.2646610034389305, 0.2662859721860992, 0.2679031903699164, 0.2695187872334638, 0.2713376395334253, 0.27321538005337553, 0.2750981424741478, 0.2770230550567317, 0.2791941123851346, 0.2815090835887365, 0.2837090193702088, 0.2860540123392066, 0.2884883577989818, 0.29094375187422356, 0.2932269985373917, 0.29549018323178056, 0.2975084198832678, 0.2995187346546632, 0.3015996983733707, 0.3037213852829539, 0.30578130856500313, 0.30780442804428043, 0.30988492263002065, 0.3121054437597244, 0.3141326983193317, 0.3163019478808953, 0.31837526235866487, 0.32058481702493385, 0.32264663403477123, 0.32460365641265515, 0.3267354587197444, 0.32872021469264756, 0.33091184803045126, 0.3330108739511448, 0.3350316940233381, 0.3371897160780007, 0.33938853815899717, 0.34168051269878946, 0.34419005442904044, 0.34679252361196927, 0.3492371628594539, 0.35189542041152544, 0.354522822524467, 0.3572373857916423, 0.3599103763374811, 0.36286194967063173, 0.36575702640077795, 0.3688243241598403, 0.37193902740064183, 0.3752584165486825, 0.3788182576206025, 0.3825852736266867, 0.3864981792560302, 0.39043471842940436, 0.3947379222591635, 0.39973297543653624, 0.4050713539355596, 0.4114439013634192, 0.41865591927333884, 0.4265020241012912, 0.43588177821201757, 0.44669333560303004, 0.46018566827986973, 0.4779463536492443, 0.5016569920844327, 0.5350486636984411, 0.588245015700356, 1.0]\n",
            "NPV:  [nan, 1.0, 0.9996823705835808, 0.9993830288001363, 0.9992098420007837, 0.9990732883033367, 0.9989397113933753, 0.998817903559844, 0.9987055909190681, 0.9986021146216063, 0.9984943355672642, 0.9983666734437838, 0.9982719962028415, 0.9981896743016346, 0.9981134221894264, 0.9980390039416266, 0.997963868930722, 0.997896767403012, 0.99782965639989, 0.9977624792193227, 0.9977015157588192, 0.9976430491813831, 0.9975809317506195, 0.9975196607457852, 0.9974537644499321, 0.9973914429667988, 0.9973256598564961, 0.9972666423781837, 0.9972105896553652, 0.9971534973120701, 0.9970905173060229, 0.997033421493823, 0.9969652303127471, 0.9969071431602972, 0.9968481493400458, 0.9967821652283017, 0.99669746255536, 0.9966262294009356, 0.9965564067348772, 0.9964732438148289, 0.9963873958147583, 0.9963115260816812, 0.9962319876427624, 0.9961401530254735, 0.9960557484065742, 0.9959757285207523, 0.9958982001995407, 0.9958146825650478, 0.9957543534130336, 0.9956642216979614, 0.9955822816834422, 0.9955029007049113, 0.9954271571489942, 0.9953405020007953, 0.9952498951755149, 0.9951595355059368, 0.9950667265412781, 0.9949708263886152, 0.9948719284535903, 0.9947576353101911, 0.9946579931726265, 0.9945513974266674, 0.9944294589251109, 0.9943233328747639, 0.9941910808395938, 0.9940803287953208, 0.9939605343553055, 0.9938176941856067, 0.9936792985292148, 0.9935372799970725, 0.9933967991437884, 0.9932743215421941, 0.9931404718995235, 0.9930031484124762, 0.9928775997698821, 0.9927260111957311, 0.9925798303410306, 0.9924221311382551, 0.9922796349488242, 0.9921062519953326, 0.9919318385103613, 0.9917539357752715, 0.9915580157763063, 0.991353020457118, 0.9911263108922682, 0.9909183627723482, 0.990650712638379, 0.9903930535934438, 0.9901214699520376, 0.9898136217275265, 0.9894900032550383, 0.9891167961692364, 0.98870360438564, 0.9882190501240404, 0.9876746363500913, 0.9869913843877984, 0.9861692990851559, 0.9851389369300784, 0.9836396271156074, 0.9808817284581839, 0.9613187966375757]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zNGoQ_lQiww",
        "outputId": "dc488324-7fdb-4470-c837-d2a6dff55155"
      },
      "source": [
        "#save output\n",
        "recall_85 = [1.0, 1.0, 0.9939652870493992, 0.9875300400534045, 0.9837116154873164, 0.9806675567423231, 0.977690253671562, 0.9749666221628839, 0.9724432576769025, 0.9701068090787717, 0.9676769025367156, 0.9648197596795728, 0.9626702269692924, 0.9607877169559412, 0.9590387182910547, 0.9573297730307077, 0.955607476635514, 0.9540587449933244, 0.9525100133511348, 0.9509612817089452, 0.9495460614152202, 0.9481842456608812, 0.9467423230974633, 0.9453137516688919, 0.9437783711615487, 0.9423230974632844, 0.9407877169559412, 0.9393991989319093, 0.9380774365821095, 0.9367289719626168, 0.9352469959946595, 0.9338985313751669, 0.9322963951935914, 0.9309212283044058, 0.9295193591455274, 0.9279572763684913, 0.9259679572763685, 0.9242723631508678, 0.92260347129506, 0.9206275033377838, 0.9185847797062751, 0.9167556742323097, 0.9148331108144192, 0.912630173564753, 0.9105874499332444, 0.9086381842456609, 0.9067423230974633, 0.904712950600801, 0.9032176234979973, 0.9010413885180241, 0.8990520694259012, 0.8971161548731642, 0.895260347129506, 0.8931508678237651, 0.8909479305740988, 0.8887449933244326, 0.886475300400534, 0.8841388518024033, 0.8817222963951936, 0.8789452603471295, 0.8765020026702269, 0.8738985313751669, 0.8709345794392523, 0.8683311081441922, 0.865113484646195, 0.8623898531375167, 0.859452603471295, 0.8559679572763685, 0.8525767690253672, 0.8490921228304406, 0.845634178905207, 0.8425901201602136, 0.8392656875834446, 0.8358611481975968, 0.8327236315086782, 0.8289586114819759, 0.8253137516688919, 0.821388518024032, 0.8178104138851803, 0.8134846461949266, 0.8091188251001336, 0.8046595460614152, 0.7997463284379173, 0.7945927903871829, 0.7888918558077437, 0.7836315086782376, 0.7769025367156208, 0.7703871829105474, 0.7634846461949266, 0.7556608811748998, 0.7473831775700934, 0.7378237650200267, 0.7272229639519359, 0.7147530040053405, 0.700694259012016, 0.6830040053404539, 0.661588785046729, 0.6346061415220293, 0.5952469959946596, 0.5227369826435248, 0.0]\n",
        "\n",
        "prec_85 = [0.03868120336242428, 0.043130502882085, 0.14503827204027284, 0.175069941821659, 0.18779342723004694, 0.19648661011644425, 0.2032134978007798, 0.20853799232386, 0.21310098861585003, 0.2171344386138969, 0.22069467408415622, 0.22368286650839295, 0.22653626107091354, 0.22919539717371434, 0.23162945478466124, 0.23390103634886825, 0.23595479689591287, 0.23796821717817562, 0.23986484214773224, 0.24161781866536405, 0.24338669605152388, 0.24512808830534097, 0.24676798012242526, 0.24847519248720845, 0.25020263550032384, 0.25184386964635525, 0.25348216469775675, 0.2551659860886468, 0.25678303072829867, 0.25842845619191795, 0.26004350763610984, 0.26157470598133986, 0.2631342934876815, 0.2646610034389305, 0.2662859721860992, 0.2679031903699164, 0.2695187872334638, 0.2713376395334253, 0.27321538005337553, 0.2750981424741478, 0.2770230550567317, 0.2791941123851346, 0.2815090835887365, 0.2837090193702088, 0.2860540123392066, 0.2884883577989818, 0.29094375187422356, 0.2932269985373917, 0.29549018323178056, 0.2975084198832678, 0.2995187346546632, 0.3015996983733707, 0.3037213852829539, 0.30578130856500313, 0.30780442804428043, 0.30988492263002065, 0.3121054437597244, 0.3141326983193317, 0.3163019478808953, 0.31837526235866487, 0.32058481702493385, 0.32264663403477123, 0.32460365641265515, 0.3267354587197444, 0.32872021469264756, 0.33091184803045126, 0.3330108739511448, 0.3350316940233381, 0.3371897160780007, 0.33938853815899717, 0.34168051269878946, 0.34419005442904044, 0.34679252361196927, 0.3492371628594539, 0.35189542041152544, 0.354522822524467, 0.3572373857916423, 0.3599103763374811, 0.36286194967063173, 0.36575702640077795, 0.3688243241598403, 0.37193902740064183, 0.3752584165486825, 0.3788182576206025, 0.3825852736266867, 0.3864981792560302, 0.39043471842940436, 0.3947379222591635, 0.39973297543653624, 0.4050713539355596, 0.4114439013634192, 0.41865591927333884, 0.4265020241012912, 0.43588177821201757, 0.44669333560303004, 0.46018566827986973, 0.4779463536492443, 0.5016569920844327, 0.5350486636984411, 0.588245015700356, 1.0]\n",
        "\n",
        "#f2 = 5*(recall_85*prec_85)/((4*prec_85)+recall_85)\n",
        "\n",
        "cutoffs_used = np.linspace(0,1,101)\n",
        "\n",
        "np.trapz(recall_85, prec_85)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5666738402645227"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "YRhLyISWRseR",
        "outputId": "0c0740d8-50d0-4653-a9ca-096c7ef44e62"
      },
      "source": [
        "#Plotting graph\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure()\n",
        "ax = plt.axes()\n",
        "\n",
        "plt.title(\"Precision Recall for Model 85 Based on Test Set\")\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "ax.plot(recall_85, prec_85)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fb9e77c4150>]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}