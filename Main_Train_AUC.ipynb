{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Main_Train.ipynb","provenance":[{"file_id":"18e0tat6DRYUnIY8yBw6DiChURJIoYyRZ","timestamp":1633111864482}],"collapsed_sections":[],"mount_file_id":"1UlvvKyATDBmeBoBKYlh5f6NQbnweC8aF","authorship_tag":"ABX9TyP4bpXj1CDXzXSRJjxsQfSd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Oi9J8g5glgnI","executionInfo":{"status":"ok","timestamp":1634090010238,"user_tz":-780,"elapsed":315,"user":{"displayName":"Anshul Jain","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggx9d4Ome0g_3EXPNC-N-LYbH04x9MpXgEmOxbUkQ=s64","userId":"01041003224467151272"}}},"source":["from os.path import join\n","\n","main_dir = \"/content/drive/MyDrive/Fire_Mapping_Project/\""],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RlqW2m9Dklhp","executionInfo":{"status":"ok","timestamp":1634090012407,"user_tz":-780,"elapsed":272,"user":{"displayName":"Anshul Jain","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggx9d4Ome0g_3EXPNC-N-LYbH04x9MpXgEmOxbUkQ=s64","userId":"01041003224467151272"}},"outputId":"a79ccc39-8d92-49e0-8b3d-79c9700803cf"},"source":["model_dir = join(main_dir,\"model\")\n","data_dir = join(main_dir, \"data\")\n","\n","print(\"model_dir\", model_dir)\n","print(\"data_dir\", data_dir)"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["model_dir /content/drive/MyDrive/Fire_Mapping_Project/model\n","data_dir /content/drive/MyDrive/Fire_Mapping_Project/data\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qDbkaZsfk2Ou","executionInfo":{"status":"ok","timestamp":1634090013646,"user_tz":-780,"elapsed":5,"user":{"displayName":"Anshul Jain","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggx9d4Ome0g_3EXPNC-N-LYbH04x9MpXgEmOxbUkQ=s64","userId":"01041003224467151272"}},"outputId":"9c5adb86-aea4-4258-a58b-0f0086444c86"},"source":["cd $model_dir"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Fire_Mapping_Project/model\n"]}]},{"cell_type":"code","metadata":{"id":"mnSmoJ1R-UIj","executionInfo":{"status":"ok","timestamp":1634090044344,"user_tz":-780,"elapsed":27171,"user":{"displayName":"Anshul Jain","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggx9d4Ome0g_3EXPNC-N-LYbH04x9MpXgEmOxbUkQ=s64","userId":"01041003224467151272"}}},"source":["import argparse\n","import os\n","import random\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from torch import FloatTensor\n","# import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","\n","from net.unet import U_Net\n","from net.attention_unet import AttU_Net\n","from dataset import FireDataset\n","\n","def set_seed(args):\n","    random.seed(args.seed)\n","    np.random.seed(args.seed)\n","    torch.manual_seed(args.seed)\n","\n","def get_dataset(img_dir, mask_dir, transform_mode='basic'):\n","    return FireDataset(img_dir, mask_dir, transform_mode)\n","\n","# +\n","def evaluate(args, model, test_dataloader):\n","    model.eval()\n","    criterion = nn.BCELoss()\n","    eval_losses = []\n","    sensitivities = []\n","    specificities = []\n","    ppvs = []\n","    npvs = []\n","    f1s = []\n","\n","    for step, (images, masks) in enumerate(test_dataloader):\n","\n","        if args.cuda:\n","            images = images.cuda(args.device_id)\n","            masks = masks.cuda(args.device_id)\n","\n","        with torch.no_grad():\n","            output_masks = model(images)\n","            output_masks = torch.sigmoid(output_masks)\n","            loss = criterion(output_masks, masks)\n","            eval_losses.append(loss.item())\n","            \n","            output_masks = output_masks.detach().cpu().numpy()\n","            output_masks = np.where(output_masks > args.cutoff, 1, 0)\n","            masks = masks.detach().cpu().numpy()\n","            \n","            #Scoring\n","\n","            tp = ((output_masks == 1) & (masks == 1)).sum()\n","            tn = ((output_masks == 0) & (masks == 0)).sum()\n","            fp = ((output_masks == 1) & (masks == 0)).sum()\n","            fn = ((output_masks == 0) & (masks == 1)).sum()\n","            \n","#             print(\"tp, tn, fp ,fn\", tp, tn, fp ,fn)\n","            \n","            sensitivity = tp / (tp + fn)\n","            specificity = tn / (fp + tn)\n","            ppv = tp / (fp + tp)\n","            npv = tn / (fn + tn)\n","            f1 = 2*tp/(2*tp + fp + fn)\n","            \n","            sensitivities.append(sensitivity)\n","            specificities.append(specificity)\n","            ppvs.append(ppv)\n","            npvs.append(npv)\n","            f1s.append(f1)\n","\n","#     return np.mean(eval_losses)\n","    return np.mean(eval_losses), np.mean(sensitivities), np.mean(specificities), np.mean(f1s), np.mean(ppvs), np.mean(npvs)\n","\n","\n","# -\n","\n","def train(args, train_dataloader, test_dataloader):\n","\n","    epochs = args.epochs\n","    batch_size = args.batch_size\n","    learning_rate = args.lr\n","    log_interval = args.log_interval\n","\n","    # Model\n","    if args.net == 'unet':\n","        model = U_Net(img_ch=1, output_ch=1)\n","    if args.net == 'attn_unet':\n","        model = AttU_Net(img_ch=1, output_ch=1)\n","\n","    if args.cuda:\n","        model.cuda(args.device_id)\n","\n","    # Optimizer\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","    # Loss criterion - BCE: binary cross entropy loss, as 2 classes in mask\n","    criterion = nn.BCELoss()\n","\n","\n","    # Begin training\n","    print(\"Model :\", args.net)\n","    print(\"Cutoff :\", args.cutoff)\n","    print(\"Train Dataloader size :\",len(train_dataloader))\n","    print(\"Transform mode :\",args.transform_mode)\n","    print(\"Batch size :\", batch_size)\n","    print(\"Epochs :\",epochs)\n","    print(\"Begin Training\")\n","    model.train()\n","    model.zero_grad()\n","\n","    best_eval_f1 = 0.5\n","\n","    for epoch in range(epochs):\n","        epoch_losses = []\n","        for step, (images, masks) in enumerate(train_dataloader):\n","            model.train()\n","\n","            if args.cuda:\n","                images = images.cuda(args.device_id)\n","                masks = masks.cuda(args.device_id)\n","\n","            output_masks = model(images)\n","            output_masks = torch.sigmoid(output_masks)\n","            loss = criterion(output_masks, masks)\n","            # print(loss)\n","\n","            loss.backward()\n","            optimizer.step()\n","            model.zero_grad()\n","\n","            epoch_losses.append(loss.item())\n","\n","        # Printing\n","        if epoch % log_interval == 0:\n","            current_epoch_loss = np.mean(epoch_losses)\n","            eval_loss, eval_sens, eval_spec, eval_f1, eval_ppv, eval_npv = evaluate(args, model, test_dataloader)\n","            print(\"Epoch %d, Loss %.3f, Eval: Loss %.3f, Sens %.3f, Spec %.3f, F1 %.3f, PPV %.3f, NPV %.3f\" \\\n","                  %(epoch, current_epoch_loss, eval_loss, eval_sens, eval_spec, eval_f1, eval_ppv, eval_npv))\n","\n","            #Save the model with minimun evaluation sensitivity :\n","            if epoch > 10 and eval_sens != 1.0 and eval_f1 > best_eval_f1:\n","                # Save the model\n","                print(\"Saving epoch %d model\"%(epoch))\n","                torch.save(model.state_dict(), 'trained_model_'+str(epoch)+'_'+str(args.net))\n","                best_eval_f1 = eval_f1\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"ydvLubjQiWp1","executionInfo":{"status":"ok","timestamp":1634090048403,"user_tz":-780,"elapsed":368,"user":{"displayName":"Anshul Jain","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggx9d4Ome0g_3EXPNC-N-LYbH04x9MpXgEmOxbUkQ=s64","userId":"01041003224467151272"}}},"source":["class Args:\n","  def __init__(self):\n","    self.train_img_dir = join(data_dir, \"train_images\")\n","    self.train_mask_dir = join(data_dir, \"train_masks\")\n","    self.test_img_dir = join(data_dir, \"test_images\")\n","    self.test_mask_dir = join(data_dir, \"test_masks\")\n","\n","    self.net = 'attn_unet'\n","    self.epochs = 100\n","    self.batch_size = 8\n","    self.cutoff = 0.30\n","    self.lr = 0.0001\n","    self.log_interval = 1\n","    self.transform_mode = 'crop_hflip_vflip'\n","    self.device_id = 0\n","    self.seed = 10\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nR_AYr_bjMAX","executionInfo":{"status":"ok","timestamp":1634090050672,"user_tz":-780,"elapsed":7,"user":{"displayName":"Anshul Jain","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggx9d4Ome0g_3EXPNC-N-LYbH04x9MpXgEmOxbUkQ=s64","userId":"01041003224467151272"}},"outputId":"980b75c6-f1c9-4192-a34a-242195145ea2"},"source":["args = Args()\n","print(vars(args))\n","print(args.batch_size)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["{'train_img_dir': '/content/drive/MyDrive/Fire_Mapping_Project/data/train_images', 'train_mask_dir': '/content/drive/MyDrive/Fire_Mapping_Project/data/train_masks', 'test_img_dir': '/content/drive/MyDrive/Fire_Mapping_Project/data/test_images', 'test_mask_dir': '/content/drive/MyDrive/Fire_Mapping_Project/data/test_masks', 'net': 'attn_unet', 'epochs': 100, 'batch_size': 8, 'cutoff': 0.3, 'lr': 0.0001, 'log_interval': 1, 'transform_mode': 'crop_hflip_vflip', 'device_id': 0, 'seed': 10}\n","8\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VyrwyK59jYs6","outputId":"a7a5af10-44cd-445c-bb5c-849437d01f92"},"source":["# Set CUDA\n","args.cuda = True if torch.cuda.is_available() else False\n","print(\"Cuda\",args.cuda)\n","\n","# Set seed\n","set_seed(args)\n","\n","# Get datasets\n","train_dataset = get_dataset(args.train_img_dir, args.train_mask_dir, args.transform_mode)\n","test_dataset = get_dataset(args.test_img_dir, args.test_mask_dir, args.transform_mode)\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n","\n","train(args, train_dataloader, test_dataloader)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cuda True\n","Model : attn_unet\n","Cutoff : 0.3\n","Train Dataloader size : 4\n","Transform mode : crop_hflip_vflip\n","Batch size : 8\n","Epochs : 100\n","Begin Training\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:66: RuntimeWarning: invalid value encountered in long_scalars\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 0, Loss 0.598, Eval: Loss 0.647, Sens 1.000, Spec 0.000, F1 0.144, PPV 0.085, NPV nan\n","Epoch 1, Loss 0.514, Eval: Loss 0.631, Sens 1.000, Spec 0.000, F1 0.135, PPV 0.079, NPV nan\n","Epoch 2, Loss 0.463, Eval: Loss 0.610, Sens 1.000, Spec 0.000, F1 0.132, PPV 0.077, NPV nan\n","Epoch 3, Loss 0.423, Eval: Loss 0.588, Sens 1.000, Spec 0.000, F1 0.154, PPV 0.094, NPV nan\n","Epoch 4, Loss 0.410, Eval: Loss 0.557, Sens 1.000, Spec 0.000, F1 0.137, PPV 0.080, NPV nan\n","Epoch 5, Loss 0.390, Eval: Loss 0.523, Sens 1.000, Spec 0.000, F1 0.155, PPV 0.095, NPV nan\n","Epoch 6, Loss 0.376, Eval: Loss 0.472, Sens 0.347, Spec 0.182, F1 0.091, PPV 0.058, NPV 0.722\n","Epoch 7, Loss 0.371, Eval: Loss 0.441, Sens 0.063, Spec 0.610, F1 0.046, PPV 0.037, NPV 0.856\n"]}]}]}